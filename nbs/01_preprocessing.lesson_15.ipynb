{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#| default_exp preprocessing.lesson15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson15 Scripts\n",
    "> Reproducing lesson 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from cv_tools.core import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2959d9fb",
   "metadata": {},
   "source": [
    "## learner[ 1:16:01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6575868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections.abc import Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78cb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_dataset_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0ff866",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1edd10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'fashion_mnist'\n",
    "dsd = load_dataset(name)\n",
    "x, y = 'image', 'label'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e294d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniai.datasets import *\n",
    "from operator import itemgetter\n",
    "from torch.utils.data import default_collate\n",
    "from torch.utils.data import DataLoader\n",
    "from fastcore.all import *\n",
    "from miniai.training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3c957f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inplace(f):\n",
    "    def _f(b):\n",
    "        f(b)\n",
    "        return b\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a6daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b):\n",
    "    b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de271f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "tsd = dsd.with_transform(transformi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dca1f089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd['train'][0][x].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e03519c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsd['train']['image'][1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f17bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd76a0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 60000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2794c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(tsd['train'], tsd['test'], bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da9c3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_dict(ds):\n",
    "    get = itemgetter(*ds.features)\n",
    "    def _f(b): return get(default_collate(b))\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "434c172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaders:\n",
    "    def __init__(self, *dls): self.train,self.valid = dls[:2]\n",
    "\n",
    "    @classmethod\n",
    "    def from_dd(cls, dd, batch_size, as_tuple=True, **kwargs):\n",
    "        f = collate_dict(dd['train'])\n",
    "        return cls(*get_dls(*dd.values(), bs=batch_size, collate_fn=f, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72eed15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniai.conv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ea0fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def to_device(x, device=def_device):\n",
    "    if isinstance(x, torch.Tensor): return x.to(device)\n",
    "    if isinstance(x, Mapping): return {k:v.to(device) for k,v in x.items()}\n",
    "    return type(x)(to_device(o, device) for o in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2360390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = dsd.with_transform(transformi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9e1c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "\tdef __init__(self, model, dls, loss_func, opt_func=optim.SGD, lr=1e-1):\n",
    "\t\tstore_attr()\n",
    "\n",
    "\tdef one_batch(self):\n",
    "\t\tself.xb, self.yb = to_device(self.batch)\n",
    "\t\tself.preds = self.model(self.xb)\n",
    "\t\tself.loss = self.loss_func(self.preds, self.yb)\n",
    "\t\tif self.model.training:\n",
    "\t\t\tself.loss.backward()\n",
    "\t\t\tself.opt.step()\n",
    "\t\t\tself.opt.zero_grad()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tself.calc_stats()\n",
    "\t\n",
    "\tdef calc_stats(self):\n",
    "\t\tacc = (self.preds.argmax(dim=1).eq(self.yb).float().sum())\n",
    "\t\tself.accs.append(acc)\n",
    "\t\tn = len(self.yb)\n",
    "\t\tself.losses.append(self.loss*n)\n",
    "\t\tself.ns.append(n)\n",
    "\n",
    "\tdef one_epoch(self, train):\n",
    "\t\tself.model.training = train\n",
    "\t\tdl = self.dls.train if train else self.dls.valid\n",
    "\t\tfor self.num, self.batch in enumerate(dl):\n",
    "\t\t\tself.one_batch()\n",
    "\t\tn = sum(self.ns)\n",
    "\t\t#print(f'epoch {self.epoch} , {self.model.training}, {(self.losses).item()/n:.2f} , {sum(self.accs).item()/n:.2f}')\n",
    "\t\tprint(self.epoch, self.model.training, sum(self.losses).item()/n, sum(self.accs).item()/n)\n",
    "\t\n",
    "\n",
    "\tdef fit(self, n_epochs):\n",
    "\t\tself.accs, self.losses, self.ns = [], [], []\n",
    "\n",
    "\t\tself.model.to(def_device)\n",
    "\t\tself.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "\t\tself.n_epochs = n_epochs\n",
    "\t\tfor self.epoch in range(n_epochs):\n",
    "\t\t\tself.one_epoch(True)\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tself.one_epoch(False)\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25443ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dd(tsd, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e66deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, nh =28*28,50\n",
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "\n",
    "learner = Learner(model=model, dls=dls, loss_func=F.cross_entropy, opt_func=optim.SGD, lr=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f5e6de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f09f153a080>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bba7a27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f09f1539e10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4308ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True 1.1903846354166667 0.6001833333333333\n",
      "0 False 1.1394975446428572 0.6130857142857142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learner.fit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa2a347",
   "metadata": {},
   "source": [
    "> More Flexible learner we need to make it more flexible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09d9d4a",
   "metadata": {},
   "source": [
    "- let's see how we can change it if we want to use different Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfe9319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.vals, self.ns = [], []\n",
    "\n",
    "    def add(self, inp, targ=None, n=1):\n",
    "        self.last = self.calc(inp, targ)\n",
    "        self.vals.append(self.last)\n",
    "        self.ns.append(n)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        ns = torch.tensor(self.ns)\n",
    "        return (torch.tensor(self.vals)*ns).sum()/ns.sum()\n",
    "\n",
    "    def calc(self, inp, targ):\n",
    "        return inp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb2f36a",
   "metadata": {},
   "source": [
    "> Now do subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "351b2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(Metric):\n",
    "    def calc(self, inp, targ):\n",
    "        return (inp == targ).float().mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37e330f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = Accuracy()\n",
    "acc.add(torch.tensor([0,1,2,3]), torch.tensor([0,1,2,3]))\n",
    "acc.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3201b444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.53)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = Metric()\n",
    "loss.add(0.6, n=10) # we can do batching and calculate loss for each batch\n",
    "loss.add(0.5, n=20)\n",
    "loss.value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035be2ba",
   "metadata": {},
   "source": [
    "> Now with that we are able to use any metric we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119bd1a6",
   "metadata": {},
   "source": [
    "# Callback Learner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23d77d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class with_cbs:\n",
    "\t\"Decorator to add callbacks to a function.\"\n",
    "\tdef __init__(self, nm): self.nm = nm\n",
    "\tdef __call__(self, f):\n",
    "\t\t\"Call the function with the callbacks.\"\n",
    "\t\tdef _f(o, *args, **kwargs):\n",
    "\t\t\t\"Try to run the function with the callbacks.\"\n",
    "\t\t\ttry:\n",
    "\t\t\t\t# First, we call the callback function with the name 'before_' followed by the name of the function we're decorating.\n",
    "\t\t\t\t# This allows us to execute any necessary setup or preprocessing before the function is called.\n",
    "\t\t\t\to.callback(f'before_{self.nm}')\n",
    "\t\t\t\t# Next, we call the original function with the provided arguments and keyword arguments.\n",
    "\t\t\t\t# This is where the actual work of the function is done.\n",
    "\t\t\t\tf(o, *args, **kwargs)\n",
    "\t\t\t\t# Finally, we call the callback function again, this time with the name 'after_' followed by the name of the function.\n",
    "\t\t\t\t# This allows us to execute any necessary cleanup or postprocessing after the function has been called.\n",
    "\t\t\t\to.callback(f'after_{self.nm}')\n",
    "\t\t\texcept globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "\t\t\t# This line catches a specific exception that is dynamically generated based on the name of the function being decorated.\n",
    "\t\t\t# The exception name is constructed by concatenating 'Cancel' with the capitalized first letter of the function name.\n",
    "\t\t\t# If this exception is caught, the code simply passes, effectively ignoring the exception and not propagating it further.\n",
    "\t\treturn _f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49babfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def identity(*args): \n",
    "\t# This line checks if there are any arguments passed to the function. If not, it returns immediately.\n",
    "\tif not args: return \n",
    "\t# This line unpacks the arguments into a first element 'x' and the rest of the arguments in 'args'.\n",
    "\tx, *args = args\n",
    "\t# This line returns a tuple containing 'x' and the rest of the arguments if there are any. \n",
    "\t# If there are no additional arguments, it returns 'x' itself.\n",
    "\treturn (x,) + tuple(args) if args else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e5ad9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1, 2)\n",
      "(1, 'q', 3)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(identity(1))\n",
    "print(identity(1,2))\n",
    "print(identity(1,'q',3))\n",
    "print(identity())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f05a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CallbackLearner:\n",
    "    def __init__(self, model, dls, loss_func, cbs, opt_func=optim.SGD, lr=1e-1):\n",
    "        store_attr()\n",
    "\n",
    "        # Here we're looping through each callback in self.cbs and setting its learn attribute to self, \n",
    "        # which is the current CallbackLearner instance. This allows each callback to access the learner.\n",
    "        for callback in self.cbs: callback.learn = self\n",
    "\n",
    "    def one_batch(self):\n",
    "        self.xb, self.yb = to_device(self.batch)\n",
    "        self.preds = self.model(self.xb)\n",
    "        self.loss = self.loss_func(self.preds, self.yb)\n",
    "        if self.model.training:\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            self.calc_stats()\n",
    "    \n",
    "    def calc_stats(self):\n",
    "        acc = (self.preds.argmax(dim=1).eq(self.yb).float().sum())\n",
    "        self.accs.append(acc)\n",
    "        n = len(self.yb)\n",
    "        self.losses.append(self.loss*n)\n",
    "        self.ns.append(n)\n",
    "\n",
    "    def one_epoch(self, train):\n",
    "        self.model.training = train\n",
    "        dl = self.dls.train if train else self.dls.valid\n",
    "        for self.num, self.batch in enumerate(dl):\n",
    "            self.one_batch()\n",
    "        n = sum(self.ns)\n",
    "        #print(f'epoch {self.epoch} , {self.model.training}, {(self.losses).item()/n:.2f} , {sum(self.accs).item()/n:.2f}')\n",
    "        print(self.epoch, self.model.training, sum(self.losses).item()/n, sum(self.accs).item()/n)\n",
    "    \n",
    "\n",
    "    def fit(self, n_epochs):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.epochs = range(n_epochs)\n",
    "        self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "        # This is not the bottom _fit function, but the with_cbs function, \n",
    "        # which will run the callback functions of the learner\n",
    "        self._fit()\n",
    "    \n",
    "    @with_cbs('fit')\n",
    "    def _fit(self):\n",
    "        for self.epoch in self.epochs:\n",
    "            self.one_epoch(True)\n",
    "            with torch.no_grad():\n",
    "                self.one_epoch(False)\n",
    "\n",
    "    def callback(self, method_nm):\n",
    "        # Sort the callbacks based on their order attribute\n",
    "        for cb in sorted(self.cbs, key=attrgetter('order')):\n",
    "            # Attempt to call the method specified by method_nm on the callback\n",
    "            # If the method does not exist, call the identity method instead\n",
    "            getattr(cb, method_nm, self.identity)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b85c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallBack:\n",
    "\torder = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe8c4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export('01_preprocessing.lesson_15.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92126022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
